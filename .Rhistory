fitted=attributes(predict(svmfit.flex,dat[train,],decision.values=T))$decision.values
rocplot(fitted ,dat[train ,"y"],add=T,col="red")
par(mfrow=c(1,2))
rocplot(fitted ,dat[train,"y"],main="Training Data")
svmfit.flex=svm(y~., data=dat[train,], kernel="radial", gamma=50, cost=1, decision.values=T)
fitted=attributes(predict(svmfit.flex,dat[train,],decision.values=T))$decision.values
rocplot(fitted ,dat[train ,"y"],add=T,col="red")
fitted=attributes(predict(svmfit.opt,dat[-train,],decision.values=T))$decision.values
rocplot(fitted,dat[-train,"y"],main="Test Data")
fitted=attributes(predict(svmfit.flex,dat[-train,],decision.values=T))$decision.values
rocplot(fitted,dat[-train,"y"],add=T,col="red")
set.seed(1)
x=rbind(x, matrix(rnorm(50*2), ncol=2))
y=c(y, rep(0,50))
x[y==0,2]=x[y==0,2]+2
dat=data.frame(x=x, y=as.factor(y))
par(mfrow=c(1,1))
plot(x,col=(y+1))
svmfit=svm(y~., data=dat, kernel="radial", cost=10, gamma=1)
plot(svmfit , dat)
library(ISLR)
names(Khan)
dim(Khan$xtrain)
dim(Khan$xtest)
length(Khan$ytrain)
length(Khan$ytest)
table(Khan$ytrain )
table(Khan$ytest )
dat=data.frame(x=Khan$xtrain , y=as.factor(Khan$ytrain ))
out=svm(y~., data=dat, kernel="linear",cost=10)
summary(out)
table(out$fitted,dat$y)
dat.te=data.frame(x=Khan$xtest , y=as.factor(Khan$ytest ))
pred.te=predict(out, newdata=dat.te)
table(pred.te, dat.te$y)
x1 = c(3, 2, 4, 1, 2, 4, 4)
x2 = c(4, 2, 4, 4, 1, 3, 1)
colors = c("red", "red", "red", "red", "blue", "blue", "blue")
plot(x1, x2, col = colors, xlim = c(0, 5), ylim = c(0, 5))
y = as.factor(colors)
x = as.matrix(x1,x2)
View(x)
x = as.matrix(c(x1,x2))
View(x)
x = as.matrix(cbind(x1,x2))
View(x)
data = data.frame(x,y)
View(data)
svmfit=svm(y~.,data=data, kernel="linear", cost=1)
summary(svmfit)
library(e1071)
set.seed(1)
set.seed(0)
x <- rnorm(100)
y <- 4 * x^2 + 1 + rnorm(100)
class <- sample(100, 50)
y[class] <- y[class] + 3
y[-class] <- y[-class] - 3
plot(x[class], y[class], col = "red", xlab = "X", ylab = "Y", ylim = c(-6, 30))
points(x[-class], y[-class], col = "blue")
x = rnorm(100)
y = 7*x^2+9+rnorm(100)
class <- sample(100, 50)
y[class] <- y[class] + 3
y[-class] <- y[-class] - 3
plot(x[class], y[class], col = "red", xlab = "X", ylab = "Y", ylim = c(-6, 30))
points(x[-class], y[-class], col = "blue")
library(e1071)
set.seed(0)
x = rnorm(100)
y = 7*x^2+9+rnorm(100)
class <- sample(100, 50)
y[class] <- y[class] + 3
y[-class] <- y[-class] - 3
plot(x[class], y[class], col = "red", xlab = "X", ylab = "Y", ylim = c(-6, 30))
points(x[-class], y[-class], col = "blue")
class = sample(100, 50)
y[split] = y[split]+5
y[-split] = y[-split]-5
split = sample(100, 50)
y[split] = y[split]+5
y[-split] = y[-split]-5
plot(x[split], y[split], col = "blue")
points(x[-class], y[-class], col = "orange")
y = 7*x^2+9+rnorm(100)
split = sample(100, 50)
y[split] = y[split]+3
y[-split] = y[-split]-3
plot(x[split], y[split], col = "blue")
points(x[-class], y[-class], col = "orange")
set.seed(0)
x = rnorm(100)
y = 7*x^2+9+rnorm(100)
split = sample(100, 50)
y[split] = y[split]+10
y[-split] = y[-split]-10
plot(x[split], y[split], col = "blue")
points(x[-class], y[-class], col = "orange")
y = 7*x^2+9+rnorm(100)
split = sample(100, 50)
y[split] = y[split]+15
y[-split] = y[-split]-15
plot(x[split], y[split], col = "blue")
points(x[-class], y[-class], col = "orange")
y[1:50] = y[1:50]+15
y[51:100] = y[51:100]-15
plot(x[split], y[split], col = "blue")
points(x[-class], y[-class], col = "orange")
points(x[51:100], y[51:100], col = "orange")
plot(x[1:50], y[1:50], col = "blue")
points(x[51:100], y[51:100], col = "orange")
y[1:50] = y[1:50]+15
y[51:100] = y[51:100]-15
plot(x[1:50], y[1:50], col = "blue")
points(x[51:100], y[51:100], col = "orange")
set.seed(0)
x = rnorm(100)
y = 7*x^2+9+rnorm(100)
y[1:50] = y[1:50]+15
y[51:100] = y[51:100]-15
plot(x[1:50], y[1:50], col = "blue")
points(x[51:100], y[51:100], col = "orange")
set.seed(0)
x = rnorm(100)
y = 7*x^2+9+rnorm(100)
y[1:50] = y[1:50]+4
y[51:100] = y[51:100]-4
plot(x[1:50], y[1:50], col = "blue")
points(x[51:100], y[51:100], col = "orange")
set.seed(0)
x = rnorm(100)
y = 7*x^2+9+rnorm(100)
y[1:50] = y[1:50]+4
y[51:100] = y[51:100]-4
plot(x[51:100], y[51:100], col = "blue")
points(x[1:50], y[1:50], col = "orange")
set.seed(0)
x = rnorm(100)
y = -7*x^2+9+rnorm(100)
y[1:50] = y[1:50]+4
y[51:100] = y[51:100]-4
plot(x[51:100], y[51:100], col = "blue")
points(x[1:50], y[1:50], col = "orange")
set.seed(0)
x = rnorm(100)
y = -7*x^2+9+rnorm(100)
y[1:50] = y[1:50]+4
y[51:100] = y[51:100]-4
plot(x[1:50], y[1:50], col = "blue")
points(x[51:100], y[51:100], col = "orange")
library(e1071)
set.seed(0)
x1 = rnorm(100)
x2 = -7*x^2+9+rnorm(100)
x2[1:50] = x2[1:50]+4
x2[51:100] = x2[51:100]-4
plot(x1[1:50], x2[1:50], col = "blue")
points(x1[51:100], x2[51:100], col = "orange")
library(e1071)
set.seed(0)
x1 = rnorm(100)
x2 = -7*x1^2+9+rnorm(100)
x2[1:50] = x2[1:50]+4
x2[51:100] = x2[51:100]-4
plot(x1[1:50], x2[1:50], col = "blue")
points(x1[51:100], x2[51:100], col = "orange")
y = rep("Blue",50)
y = y + rep("Orange",50)
rep("Orange",50)
y = cat(y,rep("Orange",50))
cat(y,rep("Orange",50))
y = rep("Blue",50)
y = cat(y,rep("Orange",50))
?cat
y = rep("Blue",50)
y = rbind(y,rep("Orange",50))
View(y)
y = rep("Blue",50)
y = c(y,rep("Orange",50))
y
x = cbind(x1,x2)
dat = data.frame(x,y)
View(dat)
svmfit=svm(y~., data=dat, kernel="linear", cost=10,scale=FALSE)
poly.svmfit = svmfit=svm(y~., data=dat, kernel="polynomial",degree = 2, cost=10,scale=FALSE)
train = sample(100,20)
train = sample(100,80)
set.seed(0)
x1 = rnorm(100)
x2 = -7*x1^2+9+rnorm(100)
x2[1:50] = x2[1:50]+4
x2[51:100] = x2[51:100]-4
plot(x1[1:50], x2[1:50], col = "blue")
points(x1[51:100], x2[51:100], col = "orange")
y = rep("Blue",50)
y = c(y,rep("Orange",50))
x = cbind(x1,x2)
dat = data.frame(x,y)
svmfit=svm(y~., data=dat, kernel="linear", cost=10,scale=FALSE)
poly.svmfit = svmfit=svm(y~., data=dat, kernel="polynomial",degree = 2, cost=10,scale=FALSE)
train = sample(100,80)
library(e1071)
set.seed(0)
x1 = rnorm(100)
x2 = -7*x1^2+9+rnorm(100)
x2[1:50] = x2[1:50]+4
x2[51:100] = x2[51:100]-4
plot(x1[1:50], x2[1:50], col = "blue")
points(x1[51:100], x2[51:100], col = "orange")
y = rep("Blue",50)
y = c(y,rep("Orange",50))
x = cbind(x1,x2)
dat = data.frame(x,y)
svmfit=svm(y~., data=dat[train], kernel="linear", cost=10,scale=FALSE)
svmfit=svm(y~., data=dat[train,], kernel="linear", cost=10,scale=FALSE)
poly.svmfit = svmfit=svm(y~., data=dat[train,], kernel="polynomial",degree = 2, cost=10,scale=FALSE)
ypred=predict(svmfit,dat[-train,])
table(predict=ypred,truth=dat[-train,]$y)
ypred=predict(poly.svmfit,dat[-train,])
table(predict=ypred,truth=dat[-train,]$y)
plot(poly.svmfit,dat)
poly.svmfit = svmfit=svm(y~., data=dat[train,], kernel="polynomial",degree = 3, cost=10,scale=FALSE)
plot(poly.svmfit,dat)
poly.svmfit = svmfit=svm(y~., data=dat[train,], kernel="polynomial",degree = 2, cost=10,scale=FALSE)
plot(poly.svmfit,dat)
ypred=predict(poly.svmfit,dat[-train,])
poly.svmfit=svm(y~., data=dat[train,], kernel="polynomial",degree = 2, cost=10,scale=FALSE)
plot(poly.svmfit,dat)
ypred=predict(poly.svmfit,dat[-train,])
table(predict=ypred,truth=dat[-train,]$y)
svmfit=svm(y~., data=dat[train,], kernel="linear", cost=10,scale=FALSE)
poly.svmfit=svm(y~., data=dat[train,], kernel="polynomial",degree = 2, cost=10,scale=FALSE)
poly.svmfit=svm(y~., data=dat[train,], kernel="polynomial",degree = 2, cost=11,scale=FALSE)
poly.svmfit=svm(y~., data=dat[train,], kernel="polynomial",degree = 2, cost=1,scale=FALSE)
plot(poly.svmfit,dat)
poly.svmfit=svm(y~., data=dat[train,], kernel="polynomial", cost=1,scale=FALSE)
plot(poly.svmfit,dat)
ypred=predict(poly.svmfit,dat[-train,])
table(predict=ypred,truth=dat[-train,]$y)
x1=runif(500)-0.5
x2=runif(500)-0.5
y=1*(x1^2-x2^2 > 0)
plot(x1,x2, col = y)
plot(x1,x2, col=4-y)
plot(x1,x2, col=2-y)
plot(x1,x2, col=y+1)
logm = glm(y~x1+x2, family = "binomial")
preds = rep(0, 500)
probs = predict(logm, df, type = "response")
logm = glm(y~x1+x2, family = "binomial")
df = data.frame(x1,x2,y)
probs = predict(logm, df, type = "response")
preds = rep(0, 500)
preds[probs > 0.5] = 1
plot(data[preds==1,], col = "blue")
plot(df[preds==1,], col = "blue")
plot(df[preds==1,]$x1,df[preds==1,]$x2, col = "blue")
points(df[preds==0,]$x1,df[preds==0,]$x2, col = "orange")
logm2  =  glm(y~x1+x2+x1^2+x2^2+x1*x2, family = "binomial")
probs = predict(logm2, df, type = "response")
preds = rep(0, 500)
preds[probs > 0.5] = 1
plot(df[preds==1,]$x1,df[preds==1,]$x2, col = "blue")
points(df[preds==0,]$x1,df[preds==0,]$x2, col = "orange")
svmfit=svm(y~., data=df, kernel="linear", cost=10,scale=FALSE)
ypred=predict(svmfit,ddf)
ypred=predict(svmfit,df)
preds=predict(svmfit,df)
preds = rep(0, 500)
preds[probs > 0.5] = 1
plot(df[preds==1,]$x1,df[preds==1,]$x2, col = "blue")
points(df[preds==0,]$x1,df[preds==0,]$x2, col = "orange")
preds=predict(svmfit,df)
preds = rep(0, 500)
preds[probs > 0.5] = 1
plot(df[preds==1,]$x1,df[preds==1,]$x2, col = "blue")
points(df[preds==0,]$x1,df[preds==0,]$x2, col = "orange")
logm2  =  glm(y~x1+x2+x1^2+x2^2+x1*x2, family = "binomial")
probs = predict(logm2, df, type = "response")
preds = rep(0, 500)
preds[probs > 0.5] = 1
plot(df[preds==1,]$x1,df[preds==1,]$x2, col = "blue")
points(df[preds==0,]$x1,df[preds==0,]$x2, col = "orange")
svmfit=svm(y~., data=df, kernel="linear", cost=10,scale=FALSE)
preds=predict(svmfit,df)
preds = rep(0, 500)
preds[probs > 0.5] = 1
plot(df[preds==1,]$x1,df[preds==1,]$x2, col = "blue")
points(df[preds==0,]$x1,df[preds==0,]$x2, col = "orange")
probs=predict(svmfit,df)
preds = rep(0, 500)
preds[probs > 0.5] = 1
plot(df[preds==1,]$x1,df[preds==1,]$x2, col = "blue")
points(df[preds==0,]$x1,df[preds==0,]$x2, col = "orange")
poly.svmfit=svm(y~., data=df, kernel="polynomial", cost=10,scale=FALSE)
probs=predict(svmfit,df)
probs=predict(poly.svmfit,df)
preds = rep(0, 500)
preds[probs > 0.5] = 1
plot(df[preds==1,]$x1,df[preds==1,]$x2, col = "blue")
points(df[preds==0,]$x1,df[preds==0,]$x2, col = "orange")
poly.svmfit=svm(y~., data=df, kernel="polynomial", cost=10,scale=FALSE)
probs=predict(poly.svmfit,df)
preds = rep(0, 500)
preds[probs > 0.5] = 1
plot(df[preds==1,]$x1,df[preds==1,]$x2, col = "blue")
points(df[preds==0,]$x1,df[preds==0,]$x2, col = "orange")
poly.svmfit=svm(y~., data=df, kernel="polynomial", cost=10,scale=FALSE)
probs=predict(poly.svmfit,df)
preds = rep(0, 500)
preds[probs > 0.5] = 1
preds
probs=predict(poly.svmfit,df)
probs
poly.svmfit=svm(y~., data=df, kernel="radial", cost=10,scale=FALSE)
probs=predict(poly.svmfit,df)
probs
preds = rep(0, 500)
preds[probs > 0.5] = 1
preds
plot(df[preds==1,]$x1,df[preds==1,]$x2, col = "blue")
points(df[preds==0,]$x1,df[preds==0,]$x2, col = "orange")
x1 = rnorm(100)
plot(x1)
x2 = rnorm(100)
plot(x1,x2)
x2 = 3*x1+5
plot(x1,x2)
split = sample(100,50)
x2[split] = x2[split]+.01
plot(x1,x2)
x2[split] = x2[split]+.5
x2 = 3*x1+5
x2[split] = x2[split]+.5
set.seed(0)
x1 = rnorm(100)
x2 = 3*x1+5
split = sample(100,50)
x2[split] = x2[split]+.5
plot(x1,x2)
set.seed(0)
x1 = rnorm(100)
x2 = 3*x1+5
plot(x1,x2)
split = sample(100,50)
x2[split] = x2[split]+.75
plot(x1,x2)
y = rep(1,100)
y[split] = -1
plot(x1,x2, col = y+3)
dat = data.frame(x1,x2,y)
set.seed(1)
tune.out=tune(svm,y~.,data=dat,kernel="linear",ranges=list(cost=c(0.001, 0.01, 0.1, 1,5,10,100)))
summary(tune.out)
tune.out=tune(svm,y~.,data=dat,kernel="linear",ranges=list(cost=c(0.001, 0.01, 0.1, 1,5,10,100,1000)))
x1.test = rnorm(100)
x2.test = 3*x1+5
split = sample(100,50)
x2.test[split] = x2.test[split]+.75
y.test = rep(1,100)
y.test[split] = -1
dat.test = data.frame(x1.test,x2.test,y.test)
errors <- rep(0, length(cost))
cost=c(0.001, 0.01, 0.1, 1,5,10,100,1000)
errors <- rep(0, length(cost))
View(dat.test)
for (i in 1:length(cost)) {
svm.fit <- svm(y~., data = dat, kernel = "linear", cost = costs[i])
pred <- predict(svm.fit, dat.test)
test.err[i] <- sum(pred != dat.test$y.test)
}
for (i in 1:length(cost)) {
svm.fit <- svm(y~., data = dat, kernel = "linear", cost = cost[i])
pred <- predict(svm.fit, dat.test)
errors[i] <- sum(pred != dat.test$y.test)
}
errors
plot(x1.test,x2.test,col= y.test+4)
x1.test = rnorm(100)
x2.test = 3*x1+5
split = sample(100,50)
x2.test[split] = x2.test[split]+.75
y.test = rep(1,100)
y.test[split] = -1
dat.test = data.frame(x1.test,x2.test,y.test)
cost=c(0.001, 0.01, 0.1, 1,5,10,100,1000)
errors <- rep(0, length(cost))
plot(x1.test,x2.test,col= y.test+4)
plot(x1.test,x2.test,col= y.test+5)
x1.test = rnorm(100
x2.test = 3*x1+5
split = sample(100,50)
x2.test[split] = x2.test[split]+.75
y.test = rep(1,100)
y.test[split] = -1
dat.test = data.frame(x1.test,x2.test,y.test)
cost=c(0.001, 0.01, 0.1, 1,5,10,100,1000)
errors <- rep(0, length(cost))
plot(x1.test,x2.test,col= y.test+5)
for (i in 1:length(cost)) {
svm.fit <- svm(y~., data = dat, kernel = "linear", cost = cost[i])
pred <- predict(svm.fit, dat.test)
errors[i] <- sum(pred != dat.test$y.test)
}
errors
x1.test = rnorm(100)
x2.test = 3*x1+5
plot(x1.test,x2.test)
x1.test = rnorm(100)
x2.test = 3*x1.test+5
split = sample(100,50)
x2.test[split] = x2.test[split]+.75
y.test = rep(1,100)
y.test[split] = -1
dat.test = data.frame(x1.test,x2.test,y.test)
cost=c(0.001, 0.01, 0.1, 1,5,10,100,1000)
errors <- rep(0, length(cost))
plot(x1.test,x2.test,col= y.test+5)
for (i in 1:length(cost)) {
svm.fit <- svm(y~., data = dat, kernel = "linear", cost = cost[i])
pred <- predict(svm.fit, dat.test)
errors[i] <- sum(pred != dat.test$y.test)
}
errors
svm.fit <- svm(y~., data = dat, kernel = "linear", cost = 10)
pred <- predict(svm.fit, dat.test)
pred
pred = round(pred)
pred
for (i in 1:length(cost)) {
svm.fit = svm(y~., data = dat, kernel = "linear", cost = cost[i])
pred = predict(svm.fit, dat.test)
pred = round(pred)
errors[i] <- sum(pred != dat.test$y.test)
}
errors
set.seed(10)
x1.test = rnorm(100)
x2.test = 3*x1.test+5
split = sample(100,50)
x2.test[split] = x2.test[split]+.75
y.test = rep(1,100)
y.test[split] = -1
dat.test = data.frame(x1.test,x2.test,y.test)
cost=c(0.001, 0.01, 0.1, 1,5,10,100,1000)
errors <- rep(0, length(cost))
plot(x1.test,x2.test,col= y.test+5)
for (i in 1:length(cost)) {
svm.fit = svm(y~., data = dat, kernel = "linear", cost = cost[i])
pred = predict(svm.fit, dat.test)
pred = round(pred)
errors[i] <- sum(pred != dat.test$y.test)
}
errors
library(ISLR)
temp = ifelse(Auto$mpg > median(Auto$mpg), 1, 0)
Auto$mpglevel <- as.factor(temp)
View(Auto)
tune.out=tune(svm,mpglevel~.,data=Auto,kernel="linear",ranges=list(cost=c(0.001, 0.01, 0.1, 1,5,10,100,1000)))
summary(tune.out)
tune.out=tune(svm,mpglevel~.,data=Auto,kernel="polynomial",ranges=list(cost=c(0.001, 0.01, 0.1, 1,5,10,100,1000),degree = c(2,3,4)))
summary(tune.out)
tune.out=tune(svm,mpglevel~.,data=Auto,kernel="radial",ranges=list(cost=c(0.001, 0.01, 0.1, 1,5,10,100,1000),gamma = c(0.1,0.01,5,10)))
summary(tune.out)
poly.svmfit = svm(mpglevel~.,data=Auto,kernel="radial",gamma = .01, cost = 100)
rad.svmfit = svm(mpglevel~.,data=Auto,kernel="radial",gamma = .01, cost = 100)
poly.svmfit = svm(mpglevel~.,data=Auto,kernel="polynomial",degree = 3, cost = 1000)
plot(rad.svmfit,Auto)
rad.svmfit = svm(mpglevel~.,data=Auto,kernel="radial",gamma = .01, cost = 100)
rad.svmfit = svm(mpglevel~.,data=Auto,kernel="radial",gamma = .01, cost = 100)
rad.svmfit = svm(mpglevel~.,data=Auto,kernel="radial",gamma = .01, cost = 100)
poly.svmfit = svm(mpglevel~.,data=Auto,kernel="polynomial",degree = 3, cost = 1000)
plot(rad.svmfit,Auto)
plot(poly.svmfit,Auto)
plot(poly.svmfit,Auto,mpglevel~)
View(Auto)
plot(poly.svmfit,Auto,horsepower~weight)
plot(poly.svmfit,Auto,horsepower~displacement)
plot(rad.svmfit,Auto,horsepower~displacement)
plot(poly.svmfit,Auto,horsepower~displacement)
plot(rad.svmfit,Auto,horsepower~displacement)
plot(rad.svmfit,Auto,horsepower~displacement)
plot(poly.svmfit,Auto,horsepower~displacement)
plot(rad.svmfit,Auto,horsepower~displacement)
plot(poly.svmfit,Auto,cylinders~displacement)
plot(poly.svmfit,Auto,weight~acceleration)
plot(poly.svmfit,Auto,mpg~acceleration)
plot(poly.svmfit,Auto,mpg~horsepower)
plot(poly.svmfit,Auto,mpg~displacement)
plot(rad.svmfit,Auto,mpg~displacement)
plot(rad.svmfit,Auto,mpg~horsepower)
plot(rad.svmfit,Auto,mpg~weight)
plot(poly.svmfit,Auto,mpg~weight)
plot(poly.svmfit,Auto,mpg~horsepower)
plot(rad.svmfit,Auto,mpg~horsepower)
plot(poly.svmfit,Auto,mpg~horsepower)
plot(poly.svmfit,Auto,mpg~cylinders)
plot(rad.svmfit,Auto,mpg~cylinders)
plotpairs(poly.svmfit)
library(readr)
setwd("~/Desktop/Work/data-scientist-exercise01")
flat = read_csv("flattened.csv")
View(flat)
library(ggplot2)
ggplot(flat, aes(x=age, y=over_50k)) +geom_point(shape=1)
ggplot(flat, aes(x=age, y=over_50k)) +geom_point(shape=2)
ggplot(flat, aes(x=age, y=over_50k)) +geom_point(shape=1)
ggplot(flat, aes(x=age, y=over_50k)) +geom_point(shape=1)
flat.m <- melt(flat, "over_50k")
library(reshape2)
flat.m <- melt(flat, "over_50k")
ggplot(flat.m, aes(value, over_50k)) +geom_point(shape=1)
